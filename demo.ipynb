{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97e2a8-5064-4113-bb26-537e7e99d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from dac import DAC\n",
    "from audiotools import AudioSignal\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "try:\n",
    "    initialize(config_path=\"config\", version_base=\"1.3\")\n",
    "except ValueError:\n",
    "    print(\"Hydra seems to be already initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df96138-4c86-4491-9c28-a89cc544a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your checkpoint directory here\n",
    "CKPT_DIR = 'checkpoints/'  # Adjust path as needed\n",
    "\n",
    "# Choose the model variant\n",
    "MODEL = 'flowdec_75m'  # flowdec_75m or flowdec_25s\n",
    "\n",
    "assert os.path.isdir(CKPT_DIR), \"CKPT_DIR seems to not exist on your system. Did you download our checkpoints and set this path correctly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfbac4-f068-49e4-bb1c-80e486ee9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the underlying (N)DAC model\n",
    "ndac_model = {'flowdec_75m': 'ndac-75', 'flowdec_25s': 'ndac-25'}[MODEL]\n",
    "dac_model = DAC.load(os.path.join(CKPT_DIR, f'ndac/{ndac_model}/800k/dac/weights.pth'))\n",
    "dac_model.to('cuda')\n",
    "dac_model.eval()\n",
    "\n",
    "# Load the FlowDec model\n",
    "conf = compose(config_name=MODEL)\n",
    "ckpt = torch.load(os.path.join(CKPT_DIR, f'flowdec/{MODEL}/step=800000.ckpt'), map_location='cpu')\n",
    "# IMPORTANT: To use EMA weights (default), follow the code below with use_ema_weights=True\n",
    "use_ema_weights = True\n",
    "state_dict_key = '_pl_ema_state_dict' if use_ema_weights else 'state_dict'\n",
    "model = instantiate(conf['model'])\n",
    "model.load_state_dict(ckpt[state_dict_key])\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd23a9-b096-4a0e-a9b4-9d703546e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for inference\n",
    "\n",
    "# The path to the file you'd like to enhance.\n",
    "wav_path = \"testfile.wav\"\n",
    "\n",
    "assert os.path.isfile(wav_path), \"wav_path seems to not exist on your system. Did you set it correctly?\"\n",
    "# `nq` is the number of quantizers (codebooks):\n",
    "#  * for flowdec_75m: [10, 8, 6, 4] were seen during training. These represent bitrates of [7.5, 6.0, 4.5, 3.0]kbps, respectively.\n",
    "#  * for flowdec_25s: Only nq=10 was seen during training. This represents 4.0kbps.\n",
    "nq = 10\n",
    "# The solver to use for FlowDec. We use 'euler' or 'midpoint', and midpoint is generally preferable. Note that midpoint has NFE=2*N.\n",
    "solver = 'midpoint'\n",
    "# The number of solver steps for FlowDec. Our default is 3 (so NFE=6) which has a good tradeoff between inference speed and quality\n",
    "N = 3\n",
    "\n",
    "# Run inference. You can ignore the printed message \"Your vector field does not have `nn.Parameters` to optimize.\"\n",
    "with torch.inference_mode():\n",
    "    signal = AudioSignal(wav_path)\n",
    "    sr_orig = signal.sample_rate\n",
    "    signal.resample(dac_model.sample_rate)\n",
    "    signal.to(dac_model.device)\n",
    "\n",
    "    x = dac_model.preprocess(signal.audio_data, signal.sample_rate)\n",
    "    z, codes, latents, _, _ = dac_model.encode(x, n_quantizers=nq)\n",
    "    xhat_ndac = dac_model.decode(z)\n",
    "\n",
    "    xhat_flowdec = model.enhance(xhat_ndac, N=N, solver=solver)\n",
    "    if xhat_flowdec.abs().max() > 1.0:\n",
    "        print(\"Prevented clipping\")\n",
    "        xhat_flowdec = xhat_flowdec / xhat_flowdec.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81498366-39e1-4d81-8eb6-286f709f1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original signal, NDAC output, and final FlowDec output.\n",
    "display(\n",
    "    Audio(signal.audio_data.cpu()[0], rate=signal.sample_rate, normalize=False),\n",
    "    Audio(xhat_ndac.cpu()[0], rate=signal.sample_rate, normalize=False),\n",
    "    Audio(xhat_flowdec.cpu()[0], rate=signal.sample_rate, normalize=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9688e-231a-48b7-ae26-e7b12afa34a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
